{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - LSTM Using Multiple Features\n",
    "\n",
    "This example utilizes a **Long Short Term Memory (LSTM) Neural Network** to predict whether the price will go up or down.\n",
    "\n",
    "**Important!** *Before further development, you need to run the ./init.py file once to install the PyTorch dependency.*\n",
    "\n",
    "**Strategy Idea:** We will go long on 'NAS:AAPL' based on the predictions of the **LSTM NN**, depending on how confident the NN is that the price is moving up.\n",
    "\n",
    "**Feature for Learning** - logarithm of prices (close, open, high).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import qnt.data as qndata\n",
    "import qnt.backtester as qnbt\n",
    "import qnt.ta as qnta\n",
    "import qnt.stats as qns\n",
    "import qnt.graph as qngraph\n",
    "import qnt.output as qnout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import random\n",
    "\n",
    "asset_name_all = ['NAS:AAPL']\n",
    "lookback_period = 155\n",
    "train_period = 100\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Class to define our LSTM network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3, hidden_layers=64):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.lstm1 = nn.LSTMCell(input_dim, self.hidden_layers)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_layers, self.hidden_layers)\n",
    "        self.linear = nn.Linear(self.hidden_layers, 1)\n",
    "\n",
    "    def forward(self, y):\n",
    "        outputs = []\n",
    "        n_samples = y.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "\n",
    "        for time_step in range(y.size(1)):\n",
    "            x_t = y[:, time_step, :]  # Ensure x_t is [batch, input_dim]\n",
    "\n",
    "            h_t, c_t = self.lstm1(x_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1).squeeze(-1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    def set_seed(seed_value=42):\n",
    "        \"\"\"Set seed for reproducibility.\"\"\"\n",
    "        random.seed(seed_value)\n",
    "        np.random.seed(seed_value)\n",
    "        torch.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    set_seed(42)\n",
    "    model = LSTM(input_dim=3)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_features(data):\n",
    "    close_price = data.sel(field=\"close\").ffill('time').bfill('time').fillna(1)\n",
    "    open_price = data.sel(field=\"open\").ffill('time').bfill('time').fillna(1)\n",
    "    high_price = data.sel(field=\"high\").ffill('time').bfill('time').fillna(1)\n",
    "    log_close = np.log(close_price)\n",
    "    log_open = np.log(open_price)\n",
    "    features = xr.concat([log_close, log_open, high_price], \"feature\")\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_target_classes(data):\n",
    "    price_current = data.sel(field='open')\n",
    "    price_future = qnta.shift(price_current, -1)\n",
    "\n",
    "    class_positive = 1  # prices goes up\n",
    "    class_negative = 0  # price goes down\n",
    "\n",
    "    target_price_up = xr.where(price_future > price_current, class_positive, class_negative)\n",
    "    return target_price_up\n",
    "\n",
    "\n",
    "def load_data(period):\n",
    "    return qndata.stocks.load_ndx_data(tail=period, assets=asset_name_all)\n",
    "\n",
    "\n",
    "def train_model(data):\n",
    "    features_all = get_features(data)\n",
    "    target_all = get_target_classes(data)\n",
    "    models = dict()\n",
    "\n",
    "    for asset_name in asset_name_all:\n",
    "        model = get_model()\n",
    "        target_cur = target_all.sel(asset=asset_name).dropna('time', 'any')\n",
    "        features_cur = features_all.sel(asset=asset_name).dropna('time', 'any')\n",
    "        target_for_learn_df, feature_for_learn_df = xr.align(target_cur, features_cur, join='inner')\n",
    "        criterion = nn.MSELoss()\n",
    "        optimiser = optim.LBFGS(model.parameters(), lr=0.08)\n",
    "        epochs = 1\n",
    "        for i in range(epochs):\n",
    "            def closure():\n",
    "                optimiser.zero_grad()\n",
    "                feature_data = feature_for_learn_df.transpose('time', 'feature').values\n",
    "                in_ = torch.tensor(feature_data, dtype=torch.float32).unsqueeze(0)\n",
    "                out = model(in_)\n",
    "                target = torch.zeros(1, len(target_for_learn_df.values))\n",
    "                target[0, :] = torch.tensor(np.array(target_for_learn_df.values))\n",
    "                loss = criterion(out, target)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            optimiser.step(closure)\n",
    "        models[asset_name] = model\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict(models, data):\n",
    "    weights = xr.zeros_like(data.sel(field='close'))\n",
    "    for asset_name in asset_name_all:\n",
    "        features_all = get_features(data)\n",
    "        features_cur = features_all.sel(asset=asset_name).dropna('time', 'any')\n",
    "        if len(features_cur.time) < 1:\n",
    "            continue\n",
    "        feature_data = features_cur.transpose('time', 'feature').values\n",
    "        in_ = torch.tensor(feature_data, dtype=torch.float32).unsqueeze(0)\n",
    "        out = models[asset_name](in_)\n",
    "        prediction = out.detach()[0]\n",
    "        weights.loc[dict(asset=asset_name, time=features_cur.time.values)] = prediction\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-pass Version for Development and Testing Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "weights = qnbt.backtest_ml(\n",
    "    load_data=load_data,\n",
    "    train=train_model,\n",
    "    predict=predict,\n",
    "    train_period=train_period,\n",
    "    retrain_interval=360,\n",
    "    retrain_interval_after_submit=1,\n",
    "    predict_each_day=False,\n",
    "    competition_type='stocks_nasdaq100',\n",
    "    lookback_period=lookback_period,\n",
    "    start_date='2006-01-01',\n",
    "    build_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-pass Version for Participation in the Contest\n",
    "\n",
    "> Comment the code above and uncomment the code below.\n",
    "\n",
    "```python\n",
    "def print_stats(data, weights):\n",
    "    stats = qns.calc_stat(data, weights)\n",
    "    display(stats.to_pandas().tail())\n",
    "    performance = stats.to_pandas()[\"equity\"]\n",
    "    qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
    "\n",
    "\n",
    "data_train = load_data(train_period)\n",
    "models = train_model(data_train)\n",
    "\n",
    "data_predict = load_data(lookback_period)\n",
    "weights_predict = predict(models, data_predict)\n",
    "\n",
    "print_stats(data_predict, weights_predict)\n",
    "```\n",
    "\n",
    "```python\n",
    "qnout.write(weights_predict) # To participate in the competition, save this code in a separate cell.\n",
    "```\n",
    "\n",
    "###  An Example of How to Evaluate the Performance of a Machine Learning Model Over a Specific Time Period\n",
    "\n",
    "```python\n",
    "data = qndata.stocks.load_ndx_data(min_date=\"2023-07-20\", assets=asset_name_all)\n",
    "\n",
    "models = train_model(data.sel(time=slice(\"2023-09-25\", \"2024-01-02\")))\n",
    "weights_slice = predict(models, data.sel(time=slice(\"2023-09-25\", \"2024-01-02\")))\n",
    "\n",
    "print_stats(data, weights_slice.sel(time=slice(\"2023-09-25\", \"2024-01-02\")))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Strategy for Competitive Submissions\n",
    "\n",
    "To enhance your machine learning-based strategy for competitive submissions, consider the following guidelines tailored for efficiency and robustness:\n",
    "\n",
    "### Model Retraining Frequency\n",
    "- Your configuration to retrain the model daily (`retrain_interval_after_submit=1`) after competition submission is noted. For a more streamlined approach, adjust your strategy to a single-pass mode, conducive to the competition's environment. Utilize the available [precheck](https://github.com/quantiacs/toolbox/blob/main/qnt/precheck.ipynb) feature for a preliminary quality assessment of your model.\n",
    "\n",
    "### Acceleration Techniques\n",
    "To expedite the development process, you might explore:\n",
    "- **Model Simplification**: Opt for less complex machine learning models to reduce computational demands.\n",
    "- **Local Development Enhancements**: Utilize a high-performance computer locally or deploy your script on a potent server for accelerated computations.\n",
    "- **Data Volume Reduction**: Limit the dataset size to hasten model training and evaluation.\n",
    "- **Condensed Testing Phases**: Shorten the evaluation timeframe by focusing on recent performance metrics, such as examining the model's financial outcomes over the past year.\n",
    "\n",
    "### Data Preparation and Feature Engineering\n",
    "- **Pre-calculated Indicators**: Employ pre-calculated technical indicators like Exponential Moving Averages (EMA) to enrich your features without the risk of lookahead bias. Example: `g_ema = qnta.ema(data_all.sel(field=\"high\"), 15)` ensures indicators are prepared ahead of the model training phase.\n",
    "\n",
    "### Other Topics\n",
    "- [Backtest ML has too long a run time](https://quantiacs.com/community/topic/528/backtest_ml-has-too-long-a-run-time/3)\n",
    "- [Printing training performance of neural network models](https://quantiacs.com/community/topic/537/printing-training-performance-of-neural-network-models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
